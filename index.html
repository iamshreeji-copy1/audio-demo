<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Modified HiFi-GAN</title>
    <meta charset="UTF-8">
    <title>Audio samples from "Modified HiFi-GAN"</title>
    <style>
        red {color: red}
        audio {width: 250px}
    </style>
  </head>
  <body>
    <article>
      <header>
        <h1>Audio samples from "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis"</h1>
      </header>
    </article>

<!--    <p><b>Paper:</b> <a href="">arXiv</a></p>-->
<!--    <p><b>Authors</b>: </p>-->

    <div>
      <b>Abstract:</b>
     Audio deepfakes are algorithm-based deep neural networks (i.e., learning approach) based on audio generation. Deefake audio is essential in speech synthesis, restoration, and voice conversion. Effectively, generating deepfake speech is a complex task to extract localized features from speech data. In this paper, we synthesize and analyze the GAN-based deepfake audio speeches. GANs framework is a powerful tool that can build the best-in-class synthesis of any data. We used the tacotron2 synthesizer to create this model. In addition, we performed the comparative experiment of genuine vs. deep fake speech. The analysis module is done in a subjective and objective Module, where subjective evaluation uses the Mean opinion score(MOS) and preference tests like speech audiometry and degradation MOS. The objective module covers the mel-cepstral distortion(MCD), Perceptual Evaluation of Speech Quality (PESQ), and prosody-based features. Experimental evaluation with both synthesized and actual data shows the out model achieves significantly near-about quality, the same as the genuine speech. We can also use these techniques to implement audio sample corpora.
    <p></p>
    </div>

<!--     <p>For more details of our work, please refer to the <a href="https://arxiv.org/abs/2010.05646">paper</a>.<br/>
    Our implementation is available in the <a href="https://github.com/jik876/hifi-gan">github repository</a>.<br/><br/> -->
    </p>


<!--     <p class="toc_title">Contents</p>
    <div id="toc_container">
    <ul>
      <li><a href="#ss">Single Speaker (LJ Speech Dataset)</a></li> -->
<!--       <li><a href="#ms">Unseen Speakers (VCTK Dataset)</a></li>
      <li><a href="#e2e">End-to-end Speech Synthesis (LJ Speech Dataset)</a></li>
      <li><a href="#as">Ablation Studies (LJ Speech Dataset)</a></li> -->
    </ul>
    </div>

    <p>&nbsp;</p>

    <div>
      <a name="ss"><h2>Single Speaker (LJ Speech Dataset)</h2></a>
      <hr>
      <table>
        <tbody>
        <tr>
          <td nowrap width="160">Original Audio</td>
          <td><audio controls="" preload="none"><source src="samples/original_speech/LJ001-0021.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/original_speech/LJ001-0074.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/original_speech/LJ002-0209.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/original_speech/LJ002-0229.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/original_speech/LJ002-0269.wav"></a</audio></td>
        </tr>

                    <tr>
          <td nowrap width="160">90k Steps Original HiFi GAN</td>
          <td><audio controls="" preload="none"><source src="samples/90k_original_gan/LJ001-0021_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_original_gan/LJ001-0074_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_original_gan/LJ002-0209_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_original_gan/LJ002-0229_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_original_gan/LJ002-0269_generated.wav"></a</audio></td>
        </tr>

                    <tr>
          <td nowrap width="160">90k Steps Modified HiFi GAN</td>
          <td><audio controls="" preload="none"><source src="samples/90k_modified_gan/LJ001-0021_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_modified_gan/LJ001-0074_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_modified_gan/LJ002-0209_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_modified_gan/LJ002-0229_generated.wav"></audio></td>
            <td><audio controls="" preload="none"><source src="samples/90k_modified_gan/LJ002-0269_generated.wav"></a</audio></td>
        </tr>


        
        </tbody>
      </table>
    </div>
    <br><br>
<!--         <p class="toc_title">Pending</p>
    <div id="toc_container">
    <ul> -->
       <div>
      <a name="ss"><h2>0.2M Steps Audio is coming soon...The model is on the GPU</h2></a>
                 <a name="ss"><h2>Point files of the model will be uploaded here soon...</h2></a>
       </div>
<!--       <li><a href="#ss">0.2M Steps Modified HiFi GAN Audio is coming soon...The model is on the GPU</a></li>
        <li><a href="#ss">Point files of the model will be uploaded soon...</a></li> -->
<!--       <li><a href="#ms">Unseen Speakers (VCTK Dataset)</a></li>
      <li><a href="#e2e">End-to-end Speech Synthesis (LJ Speech Dataset)</a></li>
      <li><a href="#as">Ablation Studies (LJ Speech Dataset)</a></li> -->
    </ul>
    </div>
  </body>
</html>
